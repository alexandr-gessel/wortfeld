# Wortfeld

**Wortfeld** ist ein FastAPI-Projekt zur Analyse und Visualisierung deutschsprachiger Nachrichtenartikel. Es kombiniert spaCy fÃ¼r linguistische Analyse, TF-IDF zur Extraktion von SchlÃ¼sselwÃ¶rtern, MongoDB als Datenbank und Jinja2 fÃ¼r die Darstellung im Webinterface. Das Projekt bildet eine vollstÃ¤ndige Verarbeitungskette ab â€“ von der Datenerhebung und -strukturierung bis zur Anzeige der Analyseergebnisse.

## ðŸ“Œ Projektbeschreibung

Dieses Projekt basiert auf praktischer Erfahrung mit der Entwicklung eines Systems zur Medienbeobachtung deutschsprachiger Nachrichtenquellen in einem Analysezentrum (2020â€“2021). Die damals eingesetzten Methoden (Parser, MongoDB, spaCy, Benachrichtigungen) wurden in *Wortfeld* Ã¼bernommen und in einer offenen Variante weiterentwickelt.

Als Datenbasis dient eine Auswahl von Artikeln der Website [Tagesschau.de](https://tagesschau.de). Aus Ã¼ber 11â€¯000 Artikeln wurde mithilfe eines Skripts eine Stichprobe von 96 Artikeln erstellt â€“ etwa 7 bis 8 pro Monat, wobei auf thematische Vielfalt geachtet wurde.

**Umgesetzte Funktionen:**

- Speicherung strukturierter Artikel in **MongoDB**
- Lemmatisierung, POS-Filterung, Extraktion benannter EntitÃ¤ten und Nominalgruppen via **spaCy**
- Extraktion von SchlÃ¼sselwÃ¶rtern mit **TF-IDF**
- Anreicherung der Daten mit **Google NLP API** (EntitÃ¤ten, Salienz, Wikipedia-Links)
- Darstellung im Webinterface mit **FastAPI** und **Jinja2**

## ðŸ› ï¸ Installation und AusfÃ¼hrung

### 1. Projekt klonen

```bash
git clone https://github.com/geromiko/wortfeld.git
cd wortfeld
```

### 2. Virtuelle Umgebung erstellen

```bash
python3 -m venv .venv
source .venv/bin/activate
```

### 3. AbhÃ¤ngigkeiten installieren

```bash
pip install -U pip
pip install -r requirements.txt
python -m spacy download de_core_news_md
```

### 4. Umgebungsvariablen definieren

Erstelle eine Datei `.env` im Projektverzeichnis mit folgendem Inhalt:

```env
MONGO_URI=mongodb+srv://benutzer:passwort@cluster.mongodb.net/wortfeld
```

### 5. Daten laden

```bash
python scripts/load_articles.py
python scripts/tfidf_keywords.py
```

### 6. Server starten

```bash
uvicorn app.main:app --reload
```

Die Anwendung ist erreichbar unter: [http://127.0.0.1:8000](http://127.0.0.1:8000)

## ðŸ’¡ Hinweise

- Getestet mit Python 3.9 und spaCy 3.6
- Verwendete Modell: `de_core_news_md`
- FÃ¼r Google NLP wird ein eigener API-Key benÃ¶tigt (nicht im MVP enthalten)
- Die Datengrundlage besteht aus 96 Artikeln (~2.5 MB). Der vollstÃ¤ndige Tagesschau-Korpus umfasst >11â€¯000 Artikel.

## ðŸ“‚ Projektstruktur

```
.
â”œâ”€â”€ README.md
â”œâ”€â”€ about.txt
â”œâ”€â”€ app
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ routes
â”‚   â”œâ”€â”€ static
â”‚   â””â”€â”€ templates
â”‚       â”œâ”€â”€ article.html
â”‚       â”œâ”€â”€ index.html
â”‚       â””â”€â”€ projekt_wortfeld.html
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ article_google_nlp.json
â”‚   â””â”€â”€ sampled_output.json
â”œâ”€â”€ requirements.txt
â””â”€â”€ scripts
    â”œâ”€â”€ analyze.py
    â”œâ”€â”€ analyze_google_nlp.py
    â”œâ”€â”€ compare_keywords.py
    â”œâ”€â”€ entity_type_counter.py
    â”œâ”€â”€ load_articles.py
    â”œâ”€â”€ mongo_google_nlp.py
    â””â”€â”€ tfidf_keywords.py
```

## ðŸ“„ Weitere Informationen

Eine ausfÃ¼hrliche Projektbeschreibung ist auf der Website verfÃ¼gbar:  
ðŸ‘‰ [pythia.one/wortfeld](https://pythia.one/wortfeld)
